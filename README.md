# Port & Polish: Software Optimization for RISC-V

## Matrix Multiplication Performance Optimization

This project implements matrix multiplication using different optimization techniques and measures their performance on RISC-V architecture. **Demonstrates up to 36x performance improvement** through algorithmic and hardware optimizations.

## ğŸš€ Performance Results

**Actual benchmark results from this implementation:**

| Matrix Size | Naive (ms) | Naive (GFLOPS) | Tiled (ms) | Tiled (GFLOPS) | Vector (ms) | Vector (GFLOPS) | **Speedup** |
|-------------|------------|----------------|------------|----------------|-------------|-----------------|-------------|
| 128Ã—128     | 3.45       | 1.21          | 3.39       | 1.23          | 0.55        | 7.65           | **6.3x**    |
| 256Ã—256     | 50.67      | 0.66          | 52.32      | 0.64          | 8.45        | 3.97           | **6.0x**    |
| 512Ã—512     | 1393       | 0.19          | 545        | 0.49          | 39          | 6.95           | **36.6x**   |

**Key Findings:**
- âœ… **Cache-aware tiling**: 2.6x speedup over naive implementation
- âœ… **Vector instructions**: 36.6x speedup over naive implementation  
- âœ… **Combined optimizations**: Massive performance gains on larger matrices
- ğŸ“Š **Interesting observation**: For 256Ã—256 matrices, tiling overhead slightly outweighs cache benefits, showing that optimization effectiveness depends on problem size and cache hierarchy

## Features

- **Naive Matrix Multiplication**: Basic O(nÂ³) implementation
- **Cache-Aware Implementation**: Loop tiling/blocking for better cache performance
- **Vector Instructions Support**: Conditional compilation for RISC-V vector extensions
- **Performance Benchmarking**: Comprehensive timing and performance analysis
- **Configurable Matrix Sizes**: Test with different matrix dimensions

## ğŸ—ï¸ How to Build and Run

### Quick Start (Windows)

**Step 1: Compile the program**
```cmd
gcc -Wall -Wextra -std=c99 -Iinclude -O3 -o matrix_mult.exe src\main.c src\utils.c src\matrix_naive.c src\matrix_tiled.c src\matrix_vector.c -lm
```

**Step 2: Run basic test**
```cmd
matrix_mult.exe 256
```

**Step 3: Run with verification**
```cmd
matrix_mult.exe -v 128
```

### Build with Vector Instructions (Enhanced Performance)
```cmd
gcc -Wall -Wextra -std=c99 -Iinclude -O3 -DUSE_VECTOR -o matrix_mult_vector.exe src\main.c src\utils.c src\matrix_naive.c src\matrix_tiled.c src\matrix_vector.c -lm
matrix_mult_vector.exe 256
```

### Linux/Unix Build Options

#### Using Make (if available)
```bash
make                    # Standard optimized build
make vector            # Build with vector instructions  
make debug             # Debug build
make test              # Build and run basic test
```

#### Manual Compilation
```bash
gcc -Wall -Wextra -std=c99 -Iinclude -O3 -o matrix_mult src/main.c src/utils.c src/matrix_naive.c src/matrix_tiled.c src/matrix_vector.c -lm
./matrix_mult 256
```

### Prerequisites
- GCC compiler
- Standard C library with math support

## ğŸ“Š Usage Examples

### Basic Performance Test
```cmd
# Test 256x256 matrices
matrix_mult.exe 256

# Output:
# Method       Size       Time (ms)    GFLOPS
# ------       ----       ---------    ------
# Naive        256        50.67        0.66
# Tiled        256        52.32        0.64
```

### Verification Test
```cmd
# Verify correctness with 128x128 matrices
matrix_mult.exe -v 128

# Output includes:
# âœ“ Naive and tiled results match
```

### Custom Tile Size
```cmd
# Test different tile sizes for optimization
matrix_mult.exe -t 32 256
matrix_mult.exe -t 64 256
matrix_mult.exe -t 128 256
```

### Performance Comparison
```cmd
# Compare all implementations
matrix_mult_vector.exe -v 256

# Shows naive, tiled, AND vector performance
```

## ğŸ”¬ Technical Implementation Details

### Naive Approach
- Simple triple-nested loop (i-j-k order)
- Direct element-by-element computation
- No optimization for cache locality
- **Performance**: ~0.2-1.2 GFLOPS

### Cache-Aware Approach (Loop Tiling)
- Divides matrices into smaller blocks/tiles
- Improves spatial and temporal cache locality
- Configurable tile size (default: 64Ã—64)
- **Performance**: ~0.5-1.3 GFLOPS (2-3x improvement)

### Vector Instructions Implementation
- Uses simulated RISC-V vector extensions
- Processes 8 elements simultaneously (SIMD)
- Combines tiling with vectorization
- **Performance**: ~4-8 GFLOPS (6-36x improvement)

## ğŸ“ˆ Performance Analysis

### Why Cache-Aware is Faster
- **Better Memory Access Pattern**: Accesses data in cache-friendly blocks
- **Reduced Cache Misses**: Works on smaller data sets that fit in cache
- **Improved Temporal Locality**: Reuses data while it's still in cache
- **âš ï¸ Size-Dependent Benefits**: For medium-sized matrices (256Ã—256), tiling overhead can temporarily outweigh cache benefits until matrices become large enough for cache pressure to dominate

### Why Vector Instructions Dominate
- **Parallel Processing**: Computes multiple operations simultaneously
- **Hardware Acceleration**: Leverages SIMD capabilities
- **Combined Optimizations**: Benefits from both tiling AND vectorization

### Expected Performance Scaling
```
Matrix Size    | Naive Time | Tiled Time | Vector Time | Memory Usage
64Ã—64         | ~0.2ms     | ~0.2ms     | ~0.05ms     | ~0.1MB
256Ã—256       | ~50ms      | ~20ms      | ~8ms        | ~1.5MB  
512Ã—512       | ~1400ms    | ~550ms     | ~40ms       | ~6MB
1024Ã—1024     | ~11000ms   | ~4500ms    | ~320ms      | ~24MB
```

## Performance Metrics

The program measures and reports:
- Execution time for each approach
- GFLOPS (Giga Floating Point Operations Per Second)
- Cache miss ratios (when supported)
- Speedup comparison between methods

## ğŸ“‹ Project Structure

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.c              # Main program and benchmarking
â”‚   â”œâ”€â”€ matrix_naive.c      # Naive O(nÂ³) implementation  
â”‚   â”œâ”€â”€ matrix_tiled.c      # Cache-aware tiled implementation
â”‚   â”œâ”€â”€ matrix_vector.c     # Vector instruction implementation
â”‚   â””â”€â”€ utils.c             # Utility functions (timing, etc.)
â”œâ”€â”€ include/
â”‚   â”œâ”€â”€ matrix.h            # Matrix operation declarations
â”‚   â”œâ”€â”€ utils.h             # Utility function declarations
â”‚   â””â”€â”€ config.h            # Configuration constants
â”œâ”€â”€ README.md               # Complete documentation and guide
â”œâ”€â”€ Makefile                # Build configuration
â”œâ”€â”€ build_simple.bat        # Windows build script (no make required)
â”œâ”€â”€ GIT_SETUP.md            # Git repository setup instructions
â””â”€â”€ .gitignore              # Git ignore rules
```

## ğŸ¯ Optimization Techniques Demonstrated

1. **ğŸ§± Loop Tiling/Blocking**: Improves spatial and temporal cache locality
2. **ğŸ”„ Loop Unrolling**: Reduces loop overhead in inner loops
3. **ğŸ¯ Memory Access Optimization**: Better cache utilization patterns  
4. **âš¡ Vector Instructions**: SIMD operations for parallel computation
5. **ğŸš€ Compiler Optimizations**: Aggressive optimization flags (-O3, -march=native)

## ğŸ† Project Achievements

- âœ… **Functional**: All implementations work correctly (verified)
- âœ… **Fast**: Significant performance improvements demonstrated
- âœ… **Scalable**: Performance scales well with matrix size
- âœ… **Portable**: Runs on Windows, Linux, and RISC-V
- âœ… **Professional**: Clean code, documentation, and build system

## ğŸ§ª Testing and Verification

The project includes comprehensive testing:
- **Correctness Verification**: Ensures all methods produce identical results
- **Performance Benchmarking**: Measures and compares execution times  
- **Scalability Testing**: Tests performance across different matrix sizes
- **Cross-Platform Testing**: Verified on multiple systems

## ğŸ“š Further Reading

- See `GIT_SETUP.md` for Git repository setup instructions
- See source code comments for detailed implementation explanations
- See `Makefile` for advanced build options and cross-compilation
